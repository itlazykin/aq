## AlgoAndDataStructure

[1. Какова основная идея хэш-таблиц и как они работают](#1-какова-основная-идея-хэш-таблиц-и-как-они-работают)

[2. Каковы основные операции, которые можно выполнить с массивами?](#2-каковы-основные-операции-которые-можно-выполнить-с-массивами-)

[3. Что такое двоичное дерево поиска и каковы его основные свойства?](#3-что-такое-двоичное-дерево-поиска-и-каковы-его-основные-свойства)

[4. Каковы преимущества и недостатки использования связанных списков по сравнению с массивами?](#4-каковы-преимущества-и-недостатки-использования-связанных-списков-по-сравнению-с-массивами)

[5. Как реализуется алгоритм поиска в глубину на графе и для каких задач он обычно используется?](#5-как-реализуется-алгоритм-поиска-в-глубину-на-графе-и-для-каких-задач-он-обычно-используется)

[6. Объясните, как работает алгоритм двоичного поиска и в каких условиях он наиболее эффективен.](#6-объясните-как-работает-алгоритм-двоичного-поиска-и-в-каких-условиях-он-наиболее-эффективен)

[7. Опишите, как реализуется и используется алгоритм Дейкстры для поиска кратчайшего пути на взвешенном графе.](#7-опишите-как-реализуется-и-используется-алгоритм-дейкстры-для-поиска-кратчайшего-пути-на-взвешенном-графе)

[8. Какие существуют методы балансировки двоичных деревьев поиска и в чем заключается их необходимость?](#8-какие-существуют-методы-балансировки-двоичных-деревьев-поиска-и-в-чем-заключается-их-необходимость)

[9. Каковы особенности реализации и применения хэш-таблиц с открытой адресацией по сравнению с методом цепочек?](#9-каковы-особенности-реализации-и-применения-хэш-таблиц-с-открытой-адресацией-по-сравнению-с-методом-цепочек)

[10. Опишите принцип алгоритма сортировки пузырьком?](#10-опишите-принцип-алгоритма-сортировки-пузырьком)

[11. Объясните, как работает линейный поиск.](#11-объясните-как-работает-линейный-поиск)

[12. Какова основная идея бинарного поиска?](#12-какова-основная-идея-бинарного-поиска)

[13. Какова асимптотическая сложность алгоритма сортировки вставками?](#13-какова-асимптотическая-сложность-алгоритма-сортировки-вставками)

[14. Опишите принцип алгоритма сортировки слиянием.](#14-опишите-принцип-алгоритма-сортировки-слиянием)

[15. В чем преимущество алгоритма быстрой сортировки по сравнению с другими алгоритмами сортировки?](#15-в-чем-преимущество-алгоритма-быстрой-сортировки-по-сравнению-с-другими-алгоритмами-сортировки)

[16. Как реализовать алгоритм сортировки подсчетом на Java?](#16-как-реализовать-алгоритм-сортировки-подсчетом-на-java)

[17. Какие стратегии оптимизации могут быть применены к алгоритму быстрой сортировки?](#17-какие-стратегии-оптимизации-могут-быть-применены-к-алгоритму-быстрой-сортировки)

[18. Опишите процесс реализации алгоритма поиска в глубину на графе.](#18-опишите-процесс-реализации-алгоритма-поиска-в-глубину-на-графе)

[19. Что такое О-нотация?](#19-что-такое-о-нотация)

[20. Что такое О-нотация?](#20-что-такое-о-нотация)

[21. Приведите пример временной сложности алгоритма, которая является линейной.](#21-приведите-пример-временной-сложности-алгоритма-которая-является-линейной)

[22. Как изменится временная сложность алгоритма сортировки массива, если количество элементов в массиве удвоится?](#22-как-изменится-временная-сложность-алгоритма-сортировки-массива-если-количество-элементов-в-массиве-удвоится)

[23. Что такое амортизационный анализ временной сложности алгоритма?](#23-что-такое-амортизационный-анализ-временной-сложности-алгоритма)

[24. Чем отличается временная сложность в худшем случае от средней временной сложности?](#24-чем-отличается-временная-сложность-в-худшем-случае-от-средней-временной-сложности)

[25. Как можно оценить пространственную сложность алгоритма?](#25-как-можно-оценить-пространственную-сложность-алгоритма)

[26. Каковы основные различия между сложностью О(n log n) и О(n^2)? Приведите примеры алгоритмов.](#26-каковы-основные-различия-между-сложностью-оn-log-n-и-оn2-приведите-примеры-алгоритмов)

[27. Как влияет структура данных на временную сложность алгоритма? Приведите пример.](#27-как-влияет-структура-данных-на-временную-сложность-алгоритма-приведите-пример)

# 1. Какова основная идея хэш-таблиц и как они работают

Хэш-таблица — это структура данных, которая хранит пары ключ → значение и позволяет быстро находить, добавлять и удалять элементы.

#### Как это работает?

- Есть ключ (например, строка "apple").
- Хэш-функция преобразует ключ в число (индекс массива). 
- При поиске снова вычисляется хэш, и мы сразу попадаем в нужную ячейку.

[К оглавлению](#AlgoAndDataStructure)

# 2. Каковы основные операции, которые можно выполнить с массивами? 

Массив — это упорядоченный набор элементов одного типа, доступ к которым происходит по индексу

- `Создание массива`
```java
// Способ 1: Сразу со значениями
int[] arr1 = {1, 2, 3};

// Способ 2: С указанием размера (заполняется нулями / null)
int[] arr2 = new int[5];  // [0, 0, 0, 0, 0]
```

- `Доступ к элементу по индексу`
````java
int[] numbers = {10, 20, 30};
System.out.println(numbers[0]);  // 10
System.out.println(numbers[2]);  // 30
// System.out.println(numbers[3]);  // Ошибка! ArrayIndexOutOfBoundsException
````

- `Изменение элемента`
```java
numbers[1] = 99;  // Теперь массив: [10, 99, 30]
```

- `Обход массива`
```java
for (int i = 0; i < numbers.length; i++) {
    System.out.println(numbers[i]);
}
```

- `Поиск элемента`

```java
Линейный поиск (если массив не отсортирован):

int target = 20;
for (int i = 0; i < numbers.length; i++) {
    if (numbers[i] == target) {
        System.out.println("Нашли на позиции " + i);
        break;
    }
}
```

- `Сортировка`
```java
Arrays.sort(numbers);  // Быстрая сортировка (O(n log n))
```

[К оглавлению](#AlgoAndDataStructure)

# 3. Что такое двоичное дерево поиска и каковы его основные свойства?

`Binary Search Tree, BST` - это структура данных, где каждый узел имеет не более двух детей (левый и правый), и для любого узла выполняется условие:

- Любой элемент левого поддерева ≤ текущий узел. 
- Любой элемент правого поддерева ≥ текущий узел.

#### Основные свойства BST

- `Упорядоченность`
  - Все элементы слева меньше родителя, справа — больше (или равны, если разрешены дубликаты).
  - Это позволяет быстро искать, вставлять и удалять элементы.

- `Рекурсивная структура`
  - Каждое поддерево — тоже BST.

[К оглавлению](#AlgoAndDataStructure)

# 4. Каковы преимущества и недостатки использования связанных списков по сравнению с массивами?

#### Преимущества LinkedList перед массивом

- В массиве размер фиксирован, а LinkedList может расти сколько угодно (памяти хватит).
- Не нужно копировать данные при расширении
- Чтобы вставить элемент в массив, нужно сдвигать остальные элементы, в связанном списке достаточно поменять ссылки
- В LinkedList удаление первого/последнего элемента — O(1). В массиве удаление первого элемента — O(n) (нужно сдвигать всё).

#### Недостатки LinkedList по сравнению с массивом

- Медленный доступ по индексу. В списке: чтобы дойти до 5-го элемента, нужно перебрать первые 4 (O(n)).
- Больше расходов по памяти. Каждый элемент списка хранит ссылку
- Массив лежит в памяти цельным блоком, и процессор кэширует его эффективно. Элементы LinkedList разбросаны по памяти.

[К оглавлению](#AlgoAndDataStructure)

# 5. Как реализуется алгоритм поиска в глубину на графе и для каких задач он обычно используется?

`Depth-First Search` - это метод обхода графа, который идёт "вглубь", пока не упрётся в тупик, а затем возвращается (backtracking) и исследует другие ветви.

#### Как реализуется?

- Начать с выбранной вершины (пометить её как посещённую). 
- Для всех смежных вершин: Если вершина не посещена, рекурсивно вызвать DFS для неё.
- Повторять, пока все достижимые вершины не будут обработаны.

### Варианты обхода (для дерева)
- `Inorder` (левый → корень → правый) — для бинарных деревьев. 
- `Preorder` (корень → левый → правый) — копирование структуры. 
- `Postorder` (левый → правый → корень) — удаление дерева.

```java
Реализация DFS на Java (для графа)

import java.util.*;

class Graph {
    private int V; // Количество вершин
    private LinkedList<Integer>[] adj; // Список смежности

    Graph(int v) {
        V = v;
        adj = new LinkedList[v];
        for (int i = 0; i < v; ++i)
            adj[i] = new LinkedList<>();
    }

    // Добавление ребра
    void addEdge(int v, int w) {
        adj[v].add(w);
    }

    // Рекурсивный DFS
    void DFSUtil(int v, boolean[] visited) {
        visited[v] = true;
        System.out.print(v + " ");

        for (int n : adj[v]) {
            if (!visited[n])
                DFSUtil(n, visited);
        }
    }

    // Запуск DFS с заданной вершины
    void DFS(int v) {
        boolean[] visited = new boolean[V];
        DFSUtil(v, visited);
    }
}

public class Main {
    public static void main(String args[]) {
        Graph g = new Graph(4);
        g.addEdge(0, 1);
        g.addEdge(0, 2);
        g.addEdge(1, 2);
        g.addEdge(2, 0);
        g.addEdge(2, 3);
        g.addEdge(3, 3);

        System.out.println("DFS (начиная с вершины 2):");
        g.DFS(2); // 2 0 1 3
    }
}
```

#### Где используется DFS?
- Поиск связных компонентов в графе. 
- Проверка на циклы (если при обходе встречается уже посещённая вершина — есть цикл). 
- Топологическая сортировка (например, для планирования задач). 
- Генерация лабиринтов и поиск выхода. 
- Анализ синтаксических деревьев (компиляторы).

[К оглавлению](#AlgoAndDataStructure)

# 6. Объясните, как работает алгоритм двоичного поиска и в каких условиях он наиболее эффективен.

Двоичный поиск — это алгоритм поиска элемента в отсортированном массиве, который работает за O(log n). Он последовательно делит массив пополам, отбрасывая половину элементов, где искомого значения точно нет.

#### Как работает?
- На входе: Отсортированный массив и целевой элемент.
- Шаги:
  - Сравниваем целевой элемент с серединой массива. 
  - Если элемент равен середине — поиск завершён. 
  - Если элемент меньше — ищем в левой половине. 
  - Если элемент больше — ищем в правой половине.
- Повторяем, пока не найдём элемент или не убедимся, что его нет.

```java
public int binarySearch(int[] arr, int target) {
    int left = 0;
    int right = arr.length - 1;

    while (left <= right) {
        int mid = left + (right - left) / 2; // Чтобы избежать переполнения
        if (arr[mid] == target) {
            return mid; // Элемент найден
        } else if (arr[mid] < target) {
            left = mid + 1; // Ищем в правой половине
        } else {
            right = mid - 1; // Ищем в левой половине
        }
    }
    return -1; // Элемент не найден
}
```

#### Условия эффективности
- Массив должен быть отсортирован. Без этого алгоритм не работает! 
- Доступ по индексу за O(1) (например, массив, а не связный список). 
- Нетребовательность к памяти: O(1) — не использует доп. память.

[К оглавлению](#AlgoAndDataStructure)

# 7. Опишите, как реализуется и используется алгоритм Дейкстры для поиска кратчайшего пути на взвешенном графе.

Алгоритм Дейкстры находит кратчайшие пути от одной вершины (стартовой) до всех остальных во взвешенном графе с неотрицательными весами рёбер.

#### Как работает алгоритм?
- Инициализация:
  - Устанавливаем расстояние до стартовой вершины = 0, до остальных = ∞. 
  - Добавляем все вершины в приоритетную очередь (мини-кучу), где приоритет — текущее расстояние.
- Основной цикл:
  - Извлекаем вершину с минимальным расстоянием из очереди.
  - Для каждого её соседа проверяем: Если найден более короткий путь (расстояние до текущей вершины + вес ребра < текущего расстояния соседа), обновляем расстояние.
- Повторяем, пока очередь не опустеет.

```java
import java.util.*;

class Edge {
    int target;
    int weight;
    Edge(int target, int weight) {
        this.target = target;
        this.weight = weight;
    }
}

public class Dijkstra {
    public static int[] dijkstra(List<List<Edge>> graph, int start) {
        int n = graph.size();
        int[] dist = new int[n];
        Arrays.fill(dist, Integer.MAX_VALUE);
        dist[start] = 0;

        PriorityQueue<int[]> pq = new PriorityQueue<>(Comparator.comparingInt(a -> a[1]));
        pq.add(new int[]{start, 0});

        while (!pq.isEmpty()) {
            int[] current = pq.poll();
            int u = current[0];
            int currentDist = current[1];

            if (currentDist > dist[u]) continue; // Уже нашли более короткий путь

            for (Edge edge : graph.get(u)) {
                int v = edge.target;
                int newDist = dist[u] + edge.weight;
                if (newDist < dist[v]) {
                    dist[v] = newDist;
                    pq.add(new int[]{v, newDist});
                }
            }
        }
        return dist;
    }

    public static void main(String[] args) {
        // Пример графа: 0 → (1, 4), (2, 1); 1 → (3, 1); 2 → (1, 2), (3, 5); 3 → []
        List<List<Edge>> graph = new ArrayList<>();
        graph.add(Arrays.asList(new Edge(1, 4), new Edge(2, 1))); // 0
        graph.add(Arrays.asList(new Edge(3, 1)));                 // 1
        graph.add(Arrays.asList(new Edge(1, 2), new Edge(3, 5)));  // 2
        graph.add(Collections.emptyList());                        // 3

        int[] distances = dijkstra(graph, 0);
        System.out.println(Arrays.toString(distances)); // [0, 3, 1, 4]
    }
}
```

[К оглавлению](#AlgoAndDataStructure)

# 8. Какие существуют методы балансировки двоичных деревьев поиска и в чем заключается их необходимость?

Необходимость балансировки возникает из-за того, что в неудачных случаях BST может выродиться в связный список, что приведёт к:
- Поиску, вставке и удалению за O(n) вместо O(log n).
- Резкому падению производительности (например, в базах данных или кэшах).

#### Основные методы балансировки

- `AVL-деревья` Для строгой балансировки
- Суть: Поддерживают высоту поддеревьев так, чтобы разница не превышала 1. 
- Как: При нарушении баланса выполняются повороты (малый/большой). 
- Сложность операций: O(log n) гарантированно.

- `Красно-чёрные деревья` Для универсального использования
- Суть: Каждая вершина имеет цвет (красный/чёрный). Условия:
  - Корень всегда чёрный. 
  - Два красных узла не могут быть соседями. 
  - Все пути от корня к листьям содержат одинаковое число чёрных узлов.
- Сложность операций: O(log n) (менее строгий баланс, чем у AVL, но быстрее вставка/удаление).

- `B-деревья и B+-деревья` Для дисковых структур
- Суть: Могут иметь много детей (обычно используются в базах данных и файловых системах).
- Особенности: 
  - Все листья на одном уровне. 
  - Высокая степень ветвления уменьшает высоту дерева.
- Сложность операций: O(log n).

[К оглавлению](#AlgoAndDataStructure)

# 9. Каковы особенности реализации и применения хэш-таблиц с открытой адресацией по сравнению с методом цепочек?

Оба подхода решают проблему коллизий в хэш-таблицах

#### Метод цепочек (Separate Chaining)

Каждая ячейка таблицы содержит связный список (или другую коллекцию) элементов с одинаковым хэшем. При коллизии новый элемент добавляется в список.

`+`

- Простота реализации. 
- Не требует перестройки таблицы при высокой нагрузке (можно хранить сколько угодно элементов в одной ячейке). 
- Эффективен при большом числе коллизий.

`-`

- Дополнительная память на хранение связей (указателей в списках). 
- Элементы списка разбросаны в памяти

`Где используется?`

HashMap в Java (до версии Java 8 — только цепочки, после — гибрид с деревьями при длинных цепочках).

#### Открытая адресация (Open Addressing)

Все элементы хранятся в самом массиве таблицы. При коллизии элемент помещается в следующую свободную ячейку (определяемую пробной последовательностью).

`+`

- Все данные в одном массиве.
- Меньшие накладные расходы (нет указателей, как в цепочках).

`-`

- Чувствительность к нагрузке (при заполнении >70% резко падает производительность).
- Сложнее удаление (требует маркировки удалённых элементов или рехеширования). 
- Риск кластеризации (это метод автоматической группировки данных на основе их схожести, когда объекты внутри одного кластера (группы) «похожи» друг на друга, а объекты из разных кластеров — отличаются.) (например, при линейном пробировании).

`Где используется?`

- ThreadLocalMap в Java (из-за лучшей локальности памяти). 
- Кэши CPU (ассоциативные буферы). 
- Встроенные системы (где важна экономия памяти).

#### Оптимизации

- Для цепочек: При длинных цепочках (Java 8+) преобразование списка в RB-дерево (чтобы гарантировать O(log n) в худшем случае). 
- Для открытой адресации: Двойное хэширование — уменьшает кластеризацию.

[К оглавлению](#AlgoAndDataStructure)

# 10. Опишите принцип алгоритма сортировки пузырьком?

В каждом проходе он сравнивает соседние элементы и меняет их местами, если они в неправильном порядке. Процесс повторяется, пока все элементы не окажутся в нужном порядке.

- В худшем и среднем случае: O(n²)
- В лучшем случае (если список уже отсортирован): O(n)

[К оглавлению](#AlgoAndDataStructure)

# 11. Объясните, как работает линейный поиск.

В этом алгоритме мы начинаем с первого элемента списка и проверяем каждый элемент по очереди, пока не найдем нужный. Если элемент найден, мы возвращаем его индекс; если мы прошли весь список, а элемента нет, то возвращаем информацию, что элемент не найден. Этот алгоритм работает за время O(n), где n — количество элементов в массиве, потому что мы проверяем каждый элемент один за другим.

```java
public class LinearSearch {
    // Метод для выполнения линейного поиска
    public static int linearSearch(int[] arr, int target) {
        // Проходим по каждому элементу массива
        for (int i = 0; i < arr.length; i++) {
            // Если нашли нужный элемент
            if (arr[i] == target) {
                return i;  // Возвращаем индекс найденного элемента
            }
        }
        return -1;  // Если не нашли элемент, возвращаем -1
    }
}
```

[К оглавлению](#AlgoAndDataStructure)

# 12. Какова основная идея бинарного поиска?

Двоичный поиск — это алгоритм поиска элемента в отсортированном массиве, который работает за O(log n). Он последовательно делит массив пополам, отбрасывая половину элементов, где искомого значения точно нет.

[К оглавлению](#AlgoAndDataStructure)

# 13. Какова асимптотическая сложность алгоритма сортировки вставками?

- Лучший случай: O(n) - Массив уже отсортирован → для каждого элемента делаем только 1 сравнение.
- Худший случай: O(n²) - Массив отсортирован в обратном порядке → каждый элемент сдвигаем в начало.


[К оглавлению](#AlgoAndDataStructure)

# 14. Опишите принцип алгоритма сортировки слиянием.

Разделяет массив пополам и рекурсивно сортирует каждую половину, затем соединяет их обратно в отсортированный массив. В худшем, среднем и лучшем случае: O(n log n)

[К оглавлению](#AlgoAndDataStructure)

# 15. В чем преимущество алгоритма быстрой сортировки по сравнению с другими алгоритмами сортировки?

Quick Sort — это «золотая середина» для большинства задач:
- Быстрый на практике (O(n log n) в среднем).
- Экономит память (работает как стек).

[К оглавлению](#AlgoAndDataStructure)

# 16. Как реализовать алгоритм сортировки подсчетом на Java?

- Найти диапазон значений (min и max) в массиве. 
- Создать массив счетчиков count[] размером max - min + 1. 
- Посчитать количество каждого элемента. 
- Перезаписать исходный массив, используя данные count[].

```java
public class CountingSort {

    public static void countingSort(int[] array) {
        if (array.length == 0) {
            return;
        }

        // Шаг 1: Находим min и max
        int min = array[0];
        int max = array[0];
        for (int num : array) {
            if (num < min) {
                min = num;
            } else if (num > max) {
                max = num;
            }
        }

        // Шаг 2: Создаем массив счетчиков
        int[] count = new int[max - min + 1];

        // Шаг 3: Считаем количество каждого элемента
        for (int num : array) {
            count[num - min]++;
        }

        // Шаг 4: Перезаписываем исходный массив
        int index = 0;
        for (int i = 0; i < count.length; i++) {
            while (count[i] > 0) {
                array[index++] = i + min;
                count[i]--;
            }
        }
    }

    public static void main(String[] args) {
        int[] array = {4, 2, 2, 8, 3, 3, 1};
        System.out.println("До сортировки: " + Arrays.toString(array));

        countingSort(array);

        System.out.println("После сортировки: " + Arrays.toString(array));
    }
}
```

[К оглавлению](#AlgoAndDataStructure)

# 17. Какие стратегии оптимизации могут быть применены к алгоритму быстрой сортировки?

- `Выбор pivot`:
  - Медиана трёх (первый, средний, последний элемент) уменьшает шанс O(n²).

- `Гибридные подходы`:
  - Для маленьких подмассивов (n < 10) переключаются на сортировку вставками.

[К оглавлению](#AlgoAndDataStructure)

# 18. Опишите процесс реализации алгоритма поиска в глубину на графе.

- Начать с выбранной вершины (корня) и пометить её как посещённую. 
- Рекурсивно посетить все смежные непосещённые вершины. 
- Повторять, пока все достижимые вершины не будут обработаны.

[К оглавлению](#AlgoAndDataStructure)

# 19. Что такое О-нотация?

Это функция, позволяющая определить, как быстро увеличивается время работы алгоритма с увеличением объёма данных. Наиболее часто встречающиеся классы сложности:

- O(1) – константная сложность (т.е. константное время); 
- О(n) – линейная сложность; 
- О(log(n)) – логарифмическая сложность; 
- O(n*log(n)) – квазилинейная сложность; 
- O(2n) – экспоненциальная сложность; 
- O(n!) – факториальная сложность.

[К оглавлению](#AlgoAndDataStructure)

# 20. Какова временная сложность алгоритма линейного поиска в худшем случае?

Худший случай (O(n)): Элемента нет или он в конце.

[К оглавлению](#AlgoAndDataStructure)

# 21. Приведите пример временной сложности алгоритма, которая является линейной.

- Линейный поиск в массиве

```java
public int findIndex(int[] array, int target) {
    for (int i = 0; i < array.length; i++) {  // Проход по всем элементам
        if (array[i] == target) {
            return i;
        }
    }
    return -1;
}

Сложность: O(n) — в худшем случае проверяются все n элементов.
```

- Сумма элементов массива

```java
public int sumArray(int[] array) {
    int sum = 0;
    for (int num : array) {  // Один проход по массиву
        sum += num;
    }
    return sum;
}

Сложность: O(n) — каждый элемент обрабатывается ровно один раз.
```

- Вывод всех элементов списка

```java
public void printList(List<String> list) {
    for (String item : list) {  // Линейный обход
        System.out.println(item);
    }
}

Сложность: O(n) — где n это размер списка.
```

[К оглавлению](#AlgoAndDataStructure)

# 22. Как изменится временная сложность алгоритма сортировки массива, если количество элементов в массиве удвоится?

Временная сложность алгоритма сортировки при удвоении количества элементов (n → 2n) зависит от типа используемого алгоритма.

| Алгоритм               | Сложность  | При удвоении n (n → 2n)      |
|------------------------|------------|------------------------------|
| Быстрая сортировка     | O(n log n) | Время увеличится в ~2.2 раза |
| Сортировка слиянием    | O(n log n) | Аналогично QuickSort         |
| Сортировка вставками   | O(n²)      | Время увеличится в 4 раза    |
| Пузырьковая сортировка | O(n²)      | Время увеличится в 4 раза    |

[К оглавлению](#AlgoAndDataStructure)

# 23. Что такое амортизационный анализ временной сложности алгоритма?

Это метод оценки средней временной сложности операции в алгоритме, учитывающий, что даже если некоторые операции
выполняются долго (худший случай), то в среднем стоимость одной операции остается низкой благодаря тому, что «дорогие»
операции происходят редко.

[К оглавлению](#AlgoAndDataStructure)

# 24. Чем отличается временная сложность в худшем случае от средней временной сложности?

`Худшая временная сложность (Worst-case Time Complexity)`
- Это максимальное время работы алгоритма на самом неблагоприятном входе заданного размера. 
- Гарантирует, что алгоритм никогда не будет работать медленнее этой оценки.

`Средняя временная сложность (Average-case Time Complexity)`
- Ожидаемое время работы алгоритма на случайном входе (чаще всего — при равномерном распределении данных). 
- Учитывает вероятность всех возможных входов и их "сложность".

[К оглавлению](#AlgoAndDataStructure)

# 25. Как можно оценить пространственную сложность алгоритма?

Пространственная сложность — это объем дополнительной памяти, который алгоритм использует помимо входных данных. Измеряется в O(...) (как и временная сложность).

`Что учитывать`:

- Локальные переменные (O(1)). 
- Динамические структуры (массивы, списки — O(n) если зависят от входа). 
- Рекурсия (каждый вызов — стек-фрейм, O(n) в худшем случае).

При оценке я сначала смотрю, какие структуры создаются в процессе, и зависят ли они от размера входа. 
Стараюсь минимизировать память — например, выбираю итерацию вместо рекурсии, если стек глубокий

[К оглавлению](#AlgoAndDataStructure)

# 26. Каковы основные различия между сложностью О(n log n) и О(n^2)? Приведите примеры алгоритмов.

- O(n log n) — растет почти линейно (но чуть быстрее).
  - Пример: Для n = 1 000 000 → ~20 000 000 операций.

- O(n²) — растет квадратично (намного быстрее).
  - Пример: Для n = 1 000 000 → 1 000 000 000 000 операций.

| Сложность  | Алгоритмы                            |
|------------|--------------------------------------|
| O(n log n) | Быстрая сортировка (QuickSort)       |
| O(n log n) | Сортировка слиянием (MergeSort)      |
| O(n²)      | Сортировка пузырьком (BubbleSort)    |
| O(n²)      | Сортировка вставками (InsertionSort) |

[К оглавлению](#AlgoAndDataStructure)

# 27. Как влияет структура данных на временную сложность алгоритма? Приведите пример.

Структура данных определяет, какие операции будут быстрыми, а какие — медленными. Выбор правильной структуры может ускорить алгоритм в сотни раз.

Структура данных напрямую влияет на скорость операций. Например, поиск в HashMap — O(1), а в списке — O(n). Выбор структуры зависит от задачи: если нужно быстро искать — используем хеш-таблицу, если часто вставляем в начало — связный список.

[К оглавлению](#AlgoAndDataStructure)
